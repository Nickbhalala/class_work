v =matrix(c(1,2,3),nrow=3,ncol = 1)
v
w =matrix(c(4,5,6),nrow = 3,ncol = 1)
w
scalar=t(v)%*%w
scalar
m= matrix(c(1,4,3,2),nrow = 2,ncol = 2,byrow = T)
m
n=matrix(c(5,3,1,7),nrow = 2,ncol = 2,byrow = T)
n
sum=M+N
sum =m+n
sum
V=matrix(c(-4,1,7),nrow = 3,ncol = 1)
v
V
V=matrix(c(-4,1,7),nrow = 3,ncol = 1)
> v
v= matrix(c(-4,1,7),nrow = 3,ncol = 1)
w=matrix(c(0,4,20),nrow = 3,ncol = 1)
scalar= t(v)%*%w
scalar
b=-3*w
b
m=matrix(c(8,3,0,21,42,3,0,34,11),nrow = 3,ncol = 3)
m
m=matrix(c(8,21,0,3,42,34,0,3,11),nrow = 3,ncol = 3)
m
m=matrix(c(8,21,0,3,42,34,0,3,11),nrow = 3,ncol = 3)
M=matrix(c(8,21,0,3,42,34,0,3,11),nrow = 3,ncol = 3)
N=matrix(c(-6,0,5,-3,2,1,0,7,-8),nrow = 3,ncol = 3)
N
N=matrix(c(-6,0,5,-3,2,1,0,7,-8),nrow = 3,ncol = 3,byrow = T)
N
N=matrix(c(-6,-3,0,0,2,7,5,1,-8),nrow = 3,ncol = 3,byrow = T)
N
M=matrix(c(8,3,0,21,42,3,0,34,11),nrow = 3,ncol = 3,byrow = T)
M
c=M*V
c=M*v
v= matrix(c(-4,1,7),nrow = 3,ncol = 1)
v
v= matrix(c(-4,1,7),nrow = 3,ncol = 1)
w= matrix(c(0,4,20),nrow = 3,ncol = 1)
w
w= matrix(c(0,4,20),nrow = 3,ncol = 1)
v= matrix(c(-4,1,7),nrow = 3,ncol = 1)
scalar=t(v)%*%w
scalar
ans_b=-3*w
ans_b
M= matrix(c(8,21,0,3,42,34,0,3,11),nrow = 3,ncol = 3,byrow = T)
M
M= matrix(c(8,3,0,21,42,3,0,34,11),nrow = 3,ncol = 3,byrow = T)
M
ans_c=M%*%v
ans_c
N= matrix(c(-6,-3,0,02,7,5,1,-8),nrow = 3,ncol = 3,byrow = T)
N= matrix(c(-6,-3,0,0,2,7,5,1,-8),nrow = 3,ncol = 3,byrow = T)
N
ans_d=M+N
ans_d
ans_e=M-N
ans_e
N= matrix(c(1,-1,1,6,1,-2,1,0),nrow = 4,ncol = 2,byrow = T)
Z= matrix(c(1,-1,1,6,1,-2,1,0),nrow = 4,ncol = 2,byrow = T)
Z
ans_f=t(Z)%*%Z
ans_f
Y= matrix(c(0,9,0,1),nrow = 4,ncol = 1,byrow = T)
ans_h=t(z)%*%y
ans_h=t(Z)%*%Y
ans_h
ans_j=det(ans_f)
ans_j
Y= matrix(c(0,9,0,1),nrow = 4,ncol = 1,byrow = T)
Y
install.packages(c("colorspace", "e1071", "fansi", "fields", "hms", "htmlTable", "ks", "lme4", "pillar", "plot3D", "RcppArmadillo", "rlang", "stringi", "tibble", "xfun"))
data(heart failure (1))
setwd("~/Dsc-324/assigment-4")
library(MASS)
data(heart failure (1))
data(heart failure)
setwd("~/Dsc-324/assigment-4")
head(heart failure)
training_values <- read.csv(file="heart failure (1).csv", header=TRUE,  sep=",")
head(training_values)
names(training_values)
library(MASS)
heartLDA = lda(DEATH_EVENT ~ ., data=training_values)
heaetLDA
plot(heartLDA)
p = predict(heartLDA, newdata=training_values[,1:4])$class
p
table(p, heartLDA$DEATH_EVENT)
table(training_values)
library(MASS)
heart = heart
choices <- length(unique(heart$DEATH_EVENT))
choices
heart = heart failure
choices <- length(unique(heart$DEATH_EVENT))
choices
heart = heart failure(1)
choices <- length(unique(heart$DEATH_EVENT))
choices
training_values <- read.csv(file="heart failure(1).csv", header=TRUE, sep=",")
setwd("~/Dsc-324/assigment-4")
library(MASS)
training_values <- read.csv(file="heart failure(1).csv", header=TRUE, sep=",")
setwd("~/Dsc-324/assigment-4")
training_values <- read.csv(file="heart failure (1).csv", header=TRUE, sep=",")
choices <- length(unique(training_values$DEATH_EVENT))
choices
training_values$DEATH_EVENT <- as.factor(ifelse(training_values$DEATH_EVENT == 0, "No", "Yes"))
heartLDA <- lda(DEATH_EVENT ~ ., data=training_values, CV=TRUE)
heartLDA
heartLDA <- lda(DEATH_EVENT ~ ., data=training_values)
heartLDA
p = predict(heartLDA, newdata=training_values[,1:13])$class
p
plot(heartLDA, xlab = "LD1", ylab = "LD2")
table(p, training_values$DEATH_EVENT)
heartLDA2 = lda(DEATH_EVENT ~ ., data=training_values, CV=T)
heartLDA2
coef(heartLDA)
table(irisLDA2$class, training_values$DEATH_EVENT)
table(heartLDA2$class, training_values$DEATH_EVENT)
coef(heartLDA)
heartLDA = lda(DEATH_EVENT ~ ., data=training_values)
heartLDA
plot(heartLDA)
p = predict(heartLDA, newdata=training_values[,1:13])$class
p
table(p, training_values$DEATH_EVENT)
heartLDA2 = lda(DEATH_EVENT ~ ., data=training_values, CV=T)
heartLDA2
table(heartLDA2$class, training_values$DEATH_EVENT)
coef(heartLDA)
accuracy <- (376+485)/(376+485+123+41)
accuracy
table(p, training_values$DEATH_EVENT)
table1(heartLDA2$class, training_values$DEATH_EVENT)
table(heartLDA2$class, training_values$DEATH_EVENT)
sum(diag(table)/sum(table)
table1<-table(heartLDA2$class, training_values$DEATH_EVENT)
table1
heartLDA2 = lda(DEATH_EVENT ~ ., data=training_values, CV=T)
heartLDA2
table1<-table(heartLDA2$class, training_values$DEATH_EVENT)
table1
sum(diag(table1)/sum(table1)
accuracy <-sum(diag(table1)/sum(table1)
accuracy
table1<-table(heartLDA2$class, training_values$DEATH_EVENT)
table1
accuracy <-sum(diag(table1)/sum(table1)
accuracy
accuracy <-sum(diag(table1)/sum(table1))
accuracy
mean(p== training_values$DEATH_EVENT)
accuracy <-sum(diag(table1)/sum(table1))
accuracy
mean(p== training_values$DEATH_EVENT)
table1<-table(heartLDA2$class, training_values$DEATH_EVENT)
table1
accuracy <-sum(diag(table1)/sum(table1))
accuracy
dt = sort(sample(nrow(training_values), nrow(training_values)*.7))
train<-heart[dt,]
test<-heart[-dt,]
dt = sort(sample(nrow(training_values), nrow(training_values)*.7))
train<-training_values[dt,]
test<-training_values[-dt,]
table2= table(p, training_values$DEATH_EVENT)
accuracy2 <-sum(diag(table2)/sum(table2))
accuracy2
mean(p== training_values$DEATH_EVENT)
able2= table(p, training_values$DEATH_EVENT)
table2
# Compare the results of the prediction
table2= table(p, training_values$DEATH_EVENT)
table2
accuracy2 <-sum(diag(table2)/sum(table2))
accuracy2
mean(p== training_values$DEATH_EVENT)
library(caret)
modelFit<- train(heartdisease ~ ., method='lda',preProcess=c('scale', 'center'), data=training_values)
#Confusion Matrix
confusionMatrix(train$heartdisease, predict(modelFit, training_values))
library(caret)
modelFit<- train( DEATH_EVENT~ ., method='lda',preProcess=c('scale', 'center'), data=training_values)
#Confusion Matrix
confusionMatrix(train$heartdisease, predict(modelFit, training_values))
library(caret)
modelFit<- train(DEATH_EVENT ~ ., method='lda',preProcess=c('scale', 'center'), data=training_values)
#Confusion Matrix
confusionMatrix(training_values$DEATH_EVENT, predict(modelFit, training_values))
require(caTools)  # loading caTools library
library(caTools)
set.seed(123)   #  set seed to ensure you always have same random numbers generated
sample_heart = sample.split(training_values,SplitRatio = 0.70) # splits the data in the ratio mentioned in SplitRatio. After splitting marks these rows as logical TRUE and the the remaining are marked as logical FALSE
train =subset(training_values,sample_heart ==TRUE) # creates a training dataset named train1 with rows which are marked as TRUE
test=subset(training_values, sample_heart==FALSE)
library(caTools)
set.seed(123)   #  set seed to ensure you always have same random numbers generated
sample_heart = sample.split(training_values,SplitRatio = 0.70) # splits the data in the ratio mentioned in SplitRatio. After splitting marks these rows as logical TRUE and the the remaining are marked as logical FALSE
train =subset(heart,sample_heart ==TRUE) # creates a training dataset named train1 with rows which are marked as TRUE
test=subset(heart, sample_heart==FALSE)
library(caTools)
set.seed(123)   #  set seed to ensure you always have same random numbers generated
sample_heart = sample.split(training_values,SplitRatio = 0.70) # splits the data in the ratio mentioned in SplitRatio. After splitting marks these rows as logical TRUE and the the remaining are marked as logical FALSE
train =subset(training_values,sample_heart ==TRUE) # creates a training dataset named train1 with rows which are marked as TRUE
test=subset(training_values, sample_heart==FALSE)
set.seed(222)   #  set seed to ensure you always have same random numbers generated
sample_heart = sample.split(training_values,SplitRatio = 0.70) # splits the data in the ratio mentioned in SplitRatio. After splitting marks these rows as logical TRUE and the the remaining are marked as logical FALSE
train =subset(training_values,sample_heart ==TRUE) # creates a training dataset named train1 with rows which are marked as TRUE
test=subset(training_values, sample_heart==FALSE)
sample_heart = sample_heart.split(training_values,SplitRatio = 0.70) # splits the data in the ratio mentioned in SplitRatio. After splitting marks these rows as logical TRUE and the the remaining are marked as logical FALSE
train =subset(training_values,sample_heart ==TRUE) # creates a training dataset named train1 with rows which are marked as TRUE
test=subset(training_values, sample_heart==FALSE)
library(caTools)
set.seed(222)   #  set seed to ensure you always have same random numbers generated
sample_heart = sample_heart.split(training_values,SplitRatio = 0.70) # splits the data in the ratio mentioned in SplitRatio. After splitting marks these rows as logical TRUE and the the remaining are marked as logical FALSE
train =subset(training_values,sample_heart ==TRUE) # creates a training dataset named train1 with rows which are marked as TRUE
test=subset(training_values, sample_heart==FALSE)
require(caTools)  # loading caTools library
library(caTools)
set.seed(222)   #  set seed to ensure you always have same random numbers generated
sample_heart = sample_heart.split(training_values,SplitRatio = 0.70) # splits the data in the ratio mentioned in SplitRatio. After splitting marks these rows as logical TRUE and the the remaining are marked as logical FALSE
train =subset(training_values,sample_heart ==TRUE) # creates a training dataset named train1 with rows which are marked as TRUE
test=subset(training_values, sample_heart==FALSE)
install.packages(c("e1071", "fansi", "fields", "ks", "lme4", "RcppArmadillo", "stringi", "tibble", "xfun"))
require(caTools)  # loading caTools library
library(caTools)
library(caret)
library(MASS)
library(e1071)
install.packages("e1071")
library(caret)
install.packages("e1071")
library(caret)
install.packages("caTools")
set.seed(222)   #  set seed to ensure you always have same random numbers generated
sample_heart = sample_heart.split(training_values,SplitRatio = 0.70) # splits the data in the ratio mentioned in SplitRatio. After splitting marks these rows as logical TRUE and the the remaining are marked as logical FALSE
train =subset(training_values,sample_heart ==TRUE) # creates a training dataset named train1 with rows which are marked as TRUE
test=subset(training_values, sample_heart==FALSE)
install.packages("caTools")
library(caTools)
install.packages(c("e1071", "fansi", "fields", "ks", "lme4", "RcppArmadillo", "stringi", "tibble", "xfun"))
library(caTools)
set.seed(222)   #  set seed to ensure you always have same random numbers generated
sample_heart = sample_heart.split(training_values,SplitRatio = 0.70) # splits the data in the ratio mentioned in SplitRatio. After splitting marks these rows as logical TRUE and the the remaining are marked as logical FALSE
train =subset(training_values,sample_heart ==TRUE) # creates a training dataset named train1 with rows which are marked as TRUE
test=subset(training_values, sample_heart==FALSE)
set.seed(222)   #  set seed to ensure you always have same random numbers generated
sample = sample.split(training_values,SplitRatio = 0.70) # splits the data in the ratio mentioned in SplitRatio. After splitting marks these rows as logical TRUE and the the remaining are marked as logical FALSE
train =subset(training_values,sample ==TRUE) # creates a training dataset named train1 with rows which are marked as TRUE
test=subset(training_values, sample==FALSE)
modelFit<- train(DEATH_EVENT ~ ., method='lda',preProcess=c('scale', 'center'), data=train)
#Confusion Matrix
confusionMatrix(train$DEATH_EVENT, predict(modelFit, train))
install.packages("caret")
library(caret)
install.packages(c("caret", "e1071", "fansi", "fields", "ks", "lme4", "RcppArmadillo", "stringi", "tibble", "xfun"))
library(caret)
modelFit<- train(DEATH_EVENT ~ ., method='lda',preProcess=c('scale', 'center'), data=train)
#Confusion Matrix
confusionMatrix(train$DEATH_EVENT, predict(modelFit, train))
